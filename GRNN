import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import math
from sklearn.metrics import mean_squared_error

# 正常显示中文
plt.rcParams['font.sans-serif']=['SimHei']
plt.rcParams['font.sans-serif']=['Arial Unicode MS']
plt.rcParams['axes.unicode_minus']=False

def minmax(train):
    n = len(train[0])
    list1 = []
    for j in range(n):
        colmax = max(train[:, j])
        colmin = min(train[:, j])
        list1.append(colmin)
        list1.append(colmax)
    print(list1)
    return list1

def mapminmax(con_data, list1):
    m = len(con_data)
    n = len(con_data[0])
    change_data = np.zeros((m, n))
    for j in range(n):
        for i in range(m):
            change_data[i, j] = 2 * (con_data[i, j] - list1[2 * j]) / (list1[2 * j + 1] - list1[2 * j]) - 1
    return change_data

def outputmapminmax(con_data, list1):
    m = len(con_data)
    n = 1
    change_data = np.zeros((m, n))
    for i in range(m):
        change_data[i] = 2 * (con_data[i] - list1[-2]) / (list1[-1] - list1[-2]) - 1
    return change_data

def distance(trainX, testX):
    p = len(testX)
    m = len(trainX)
    sigmax = 0.002
    sigmay = 0.002
    sigmaz = 0.002
    sigma = 0.002
    Euclidean_DF_guass = np.zeros((p, m))
    for i in range(p):
        for j in range(m):
            tempx = (testX[i, 0] - trainX[j, 0]) * (testX[i, 0] - trainX[j, 0])
            tempy = (testX[i, 1] - trainX[j, 1]) * (testX[i, 1] - trainX[j, 1])
            tempz = (testX[i, 2] - trainX[j, 2]) * (testX[i, 2] - trainX[j, 2])
            tempp = np.sum((testX[i, 3:] - trainX[j, 3:]) * (testX[i, 3:] - trainX[j, 3:]))

            Euclidean_DF_guass[i, j] = np.exp((-tempx / (2 * sigmax*sigmax)) + (-tempy /(2 * sigmay*sigmay)) +
                                                  (-tempz / (2 * sigmaz*sigmaz)) + (-tempp / (2 * sigma*sigma)))
    return Euclidean_DF_guass

def sum_layer(Gauss, outputn_train1):
    m = len(Gauss)
    l = len(Gauss[0])
    n = len(outputn_train1[0])
    sum_out = np.zeros((m, n + 1))
    for i in range(m):
        sum_out[i, 0] = np.sum(Gauss[i, :])
    for i in range(m):
        total = 0.0
        for t in range(l):
            total += Gauss[i, t] * outputn_train1[t, 0]
        sum_out[i, 1] = total
    return sum_out

def output_layer(sum_out):
    m = len(sum_out)
    n = len(sum_out[0])
    prediction_result = np.zeros((m, n - 1))
    for j in range(m):
        if (sum_out[j, 0] == 0):
            prediction_result[j, 0] = 0
        else:
            prediction_result[j, 0] = sum_out[j, 1] / sum_out[j, 0]
    return prediction_result

def reverseminmax(predict_data1, bmin, bmax):
    m = len(predict_data1)
    reverse_data = np.zeros((m, 1))
    for i in range(m):
        reverse_data[i, 0] = (predict_data1[i, 0] + 1) * (bmax - bmin) / 2 + bmin
    return reverse_data

def get_mse(records_real, records_predict):
    if len(records_real) == len(records_predict):
        return sum([(x - y) ** 2 for x, y in zip(records_real, records_predict)]) / len(records_real)
    else:
        return None

def get_rmse(records_real, records_predict):
    mse = get_mse(records_real, records_predict)
    if mse:
        return math.sqrt(mse)
    else:
        return None

def get_mae(records_real, records_predict):
    if len(records_real) == len(records_predict):
        return sum([abs(x - y) for x, y in zip(records_real, records_predict)]) / len(records_real)
    else:
        return None

def R2(output_test, grnn_output):
    SSR = np.sum((grnn_output - np.mean(output_test)) ** 2)
    SST = np.sum((output_test - np.mean(output_test)) ** 2)
    R2 = SSR / SST
    return R2

def mape(records_real, records_predict):
    return np.mean(np.abs((records_predict - records_real) / records_real)) * 100

num1 = pd.read_csv('train.csv')
num2 = pd.read_csv('test.csv')

m = num1.shape[1]
n = num2.shape[1]

input_train = num1.iloc[0:, 0:m - 1].values
output_train = num1.iloc[0:, m - 1].values
input_test = num2.iloc[0:, 0:n - 1].values
output_test = num2.iloc[0:, n - 1].values

input_train[np.isnan(input_train)] = 0
output_train[np.isnan(output_train)] = 0
input_test[np.isnan(input_test)] = 0
output_test[np.isnan(output_test)] = 0

list1 = minmax(num1.iloc[1:, ].values)
inputn_train = mapminmax(input_train, list1)
inputn_test = mapminmax(input_test, list1)
outputn_train = outputmapminmax(output_train, list1)

bmin = min(output_train)
bmax = max(output_train)


Euclidean_DF_guass = distance(inputn_train, inputn_test)
sum_out = sum_layer(Euclidean_DF_guass, outputn_train)
prediction_result = output_layer(sum_out)

grnn_output=reverseminmax(prediction_result,bmin,bmax)

print('结果',output_test,grnn_output)
grnn_error = mean_squared_error( output_test,grnn_output)
print('GRNN均方误差',get_mse(output_test,grnn_output))
print('GRNN均方根误差',get_rmse(output_test,grnn_output))
print('GRNN平均绝对百分比误差',mape(output_test,grnn_output))
print('GRNN神经网络预测的均方误差为',grnn_error)
print('GRNN平均绝对误差',get_mae(output_test,grnn_output))
r=R2(output_test,grnn_output)
print('GRNN决定系数',r)

plt.figure()
plt.title("广义回归神经网络预测结果对比", size=18)
plt.plot(grnn_output, 'k-*', label='广义回归神经网络预测值')
plt.plot(output_test, 'r-o', label='实际值')
plt.xlabel('测试样本', size=18)
plt.ylabel('矿石品位值 %', size=18)
plt.legend()

plt.figure()
plt.plot(output_test, grnn_output, '*', label='实际值-预测值')
plt.title("广义回归神经网络-决定系数", size=18)
x=np.linspace(min(output_test),max(output_test),3)
y=x
plt.plot(x,y,color='green',label='y=x')
r=round(r,6)
l='R^2={}'.format(r)
plt.text(min(output_test),38,l,fontsize=15)
plt.legend(fontsize=15)
plt.xlabel('实际值 %', size=18)
plt.ylabel('预测值 %', size=18)

plt.figure()
plt.plot(grnn_error, 'k-*')
plt.title("广义回归神经网络均方误差")
plt.ylabel('均方误差')
plt.show()
